<div align="center"><h1> AI Geeks<br>
<sub><sup><em>Precision beats power. Timing beats speed.</em></sup></sub><br>

[![Group Website](https://img.shields.io/badge/Group%20Website-555555.svg?style=flat-square&logo=data:image/svg%2bxml;base64,PCFET0NUWVBFIHN2ZyBQVUJMSUMgIi0vL1czQy8vRFREIFNWRyAxLjEvL0VOIiAiaHR0cDovL3d3dy53My5vcmcvR3JhcGhpY3MvU1ZHLzEuMS9EVEQvc3ZnMTEuZHRkIj4KDTwhLS0gVXBsb2FkZWQgdG86IFNWRyBSZXBvLCB3d3cuc3ZncmVwby5jb20sIFRyYW5zZm9ybWVkIGJ5OiBTVkcgUmVwbyBNaXhlciBUb29scyAtLT4KPHN2ZyBmaWxsPSIjZmZmZmZmIiB3aWR0aD0iODAwcHgiIGhlaWdodD0iODAwcHgiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiBpZD0iaG9tZS1hbHQtMyIgY2xhc3M9Imljb24gZ2x5cGgiIHN0cm9rZT0iI2ZmZmZmZiI+Cg08ZyBpZD0iU1ZHUmVwb19iZ0NhcnJpZXIiIHN0cm9rZS13aWR0aD0iMCIvPgoNPGcgaWQ9IlNWR1JlcG9fdHJhY2VyQ2FycmllciIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIiBzdHJva2UtbGluZWpvaW49InJvdW5kIi8+Cg08ZyBpZD0iU1ZHUmVwb19pY29uQ2FycmllciI+Cg08cGF0aCBkPSJNMjEuNzEsMTAuMjlsLTktOWExLDEsMCwwLDAtMS40MiwwbC05LDlhMSwxLDAsMCwwLS4yMSwxLjA5QTEsMSwwLDAsMCwzLDEySDR2OWExLDEsMCwwLDAsMSwxSDhhMSwxLDAsMCwwLDEtMVYxNWExLDEsMCwwLDEsMS0xaDRhMSwxLDAsMCwxLDEsMXY2YTEsMSwwLDAsMCwxLDFoM2ExLDEsMCwwLDAsMS0xVjEyaDFhMSwxLDAsMCwwLC45Mi0uNjJBMSwxLDAsMCwwLDIxLjcxLDEwLjI5WiIvPgoNPC9nPgoNPC9zdmc+)](https://aigeeksgroup.github.io)

</h1></div>

## About

[AI Geeks](https://aigeeksgroup.github.io) is a research group formed by a team of enthusiastic researchers who are passionate about cutting-edge computer vision and machine learning. The group's research spans multiple disciplines, including AI for Health, Multimodal LLM Agents, 3D Generative Modeling, and Robotics. The group continually pushes the boundaries of AI research, producing significant cross-disciplinary outputs and having papers accepted at prestigious international conferences and journals. Feel free to [join us](mailto:ai.geeks@outlook.com) if you are interested in being part of our research or supporting us in other ways.

## News

<b>(07/19/2024)</b> &#127881; Our paper <a href="https://steve-zeyu-zhang.github.io/MotionAvatar/">Motion Avatar</a> has been accepted to <a href="https://bmvc2024.org/"><b>BMVC 2024</b></a>!<br>
<b>(06/18/2024)</b> &#127881; Our paper <a href="https://steve-zeyu-zhang.github.io/JointViT">JointViT</a> has been selected as <b>oral presentation</b> at <a href="https://miua2024.github.io/"><b>MIUA 2024</b></a>!<br>
<b>(05/23/2024)</b> &#127881; Our paper <a href="https://steve-zeyu-zhang.github.io/MotionAvatar/">Motion Avatar</a> has been highlighted by <a href="https://twitter.com/ai_bites/status/1792907754727744000"><b>AI Bites</b></a>!<br>
<b>(05/22/2024)</b> &#127881; Our paper <a href="https://steve-zeyu-zhang.github.io/MotionAvatar/">Motion Avatar</a> has been highlighted by <a href="https://www.reddit.com/r/languagemodeldigest/comments/1cxqebo/create_3d_avatars_with_text_prompts_with_this_new/"><b>Language Model Digest</b></a>!<br>
<b>(05/21/2024)</b> &#127881; Our paper <a href="https://steve-zeyu-zhang.github.io/MotionAvatar/">Motion Avatar</a> has been highlighted by <a href="https://x.com/CSVisionPapers/status/1792975365842817444"><b>CSVisionPapers</b></a>!<br>
<b>(05/14/2024)</b> &#127881; Our paper <a href="https://steve-zeyu-zhang.github.io/JointViT">JointViT</a> has been accepted to <a href="https://miua2024.github.io/"><b>MIUA 2024</b></a>!<br>
<b>(03/02/2024)</b> &#127881; Our paper <a href="https://steve-zeyu-zhang.github.io/DiabetesDiagnosis/">A Deep Learning Approach to Diabetes Diagnosis</a> has been accepted to <a href="https://aciids.pwr.edu.pl/2024/"><b>ACIIDS 2024</b></a>!<br>
<b>(02/10/2024)</b> &#127881; Our paper <a href="https://steve-zeyu-zhang.github.io/SegReg">SegReg</a> has been accepted to <a href="https://biomedicalimaging.org/2024/"><b>ISBI 2024</b></a>!<br>
<b>(11/16/2023)</b> &#127881; Our paper <a href="https://steve-zeyu-zhang.github.io/SegReg">SegReg</a> has been highlighted by <a href="https://wx.zsxq.com/dweb2/index/topic_detail/188418544524512"><b>CVer</b></a>!<br>
<b>(09/29/2023)</b> &#127881; Our paper <a href="https://github.com/White65534/BHSD">BHSD</a> has been accepted to <a href="https://sites.google.com/view/mlmi2023"><b>MLMI 2023</b></a>!<br>
<b>(08/23/2023)</b> &#127881; Our paper <a href="https://github.com/White65534/BHSD">BHSD</a> has been highlighted by <a href="https://wx.zsxq.com/mweb/views/topicdetail/topicdetail.html?topic_id=588155111148854&group_id=142181451122&inviter_id=585252854845544"><b>CVer</b></a>!<br>

## Research

> **XLIP: Cross-modal Attention Masked Modelling for Medical Language-Image Pre-Training**<br>
> _**Preprint**_<br>
> [![arXiv](https://img.shields.io/badge/arXiv-2407.19546-b31b1b?style=flat-square&logo=arxiv)](https://arxiv.org/abs/2407.19546) [![GitHub](https://img.shields.io/badge/GitHub-Code-1f883d?style=flat-square&logo=github)](https://github.com/White65534/XLIP) [![Papers With Code](https://img.shields.io/badge/Papers%20With%20Code-555555.svg?style=flat-square&logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2aWV3Qm94PSIwIDAgNTEyIDUxMiIgd2lkdGg9IjUxMiIgIGhlaWdodD0iNTEyIiA+PHBhdGggZD0iTTg4IDEyOGg0OHYyNTZIODh6bTE0NCAwaDQ4djI1NmgtNDh6bS03MiAxNmg0OHYyMjRoLTQ4em0xNDQgMGg0OHYyMjRoLTQ4em03Mi0xNmg0OHYyNTZoLTQ4eiIgc3Ryb2tlPSIjMjFDQkNFIiBmaWxsPSIjMjFDQkNFIj48L3BhdGg+PHBhdGggZD0iTTEwNCAxMDRWNTZIMTZ2NDAwaDg4di00OEg2NFYxMDR6bTMwNC00OHY0OGg0MHYzMDRoLTQwdjQ4aDg4VjU2eiIgc3Ryb2tlPSIjMjFDQkNFIiBmaWxsPSIjMjFDQkNFIj48L3BhdGg+PC9zdmc+)](https://paperswithcode.com/paper/xlip-cross-modal-attention-masked-modelling) [![BibTeX](https://img.shields.io/badge/BibTeX-Citation-eeeeee?style=flat-square)](https://github.com/White65534/XLIP/tree/main#citation)<br>
> <img src="https://github.com/steve-zeyu-zhang/steve-zeyu-zhang.github.io/blob/main/image/xlip.svg" width="550">

> **Motion Avatar: Generate Human and Animal Avatars with Arbitrary Motion**<br>
> [_**BMVC 2024**_](https://bmvc2024.org/)<br>
> [![Website](https://img.shields.io/badge/Website-Demo-fedcba?style=flat-square)](https://steve-zeyu-zhang.github.io/MotionAvatar/) [![arXiv](https://img.shields.io/badge/arXiv-2405.11286-b31b1b?style=flat-square&logo=arxiv)](https://arxiv.org/abs/2405.11286) [![GitHub](https://img.shields.io/badge/GitHub-Code-1f883d?style=flat-square&logo=github)](https://github.com/steve-zeyu-zhang/MotionAvatar) [![Papers With Code](https://img.shields.io/badge/Papers%20With%20Code-555555.svg?style=flat-square&logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2aWV3Qm94PSIwIDAgNTEyIDUxMiIgd2lkdGg9IjUxMiIgIGhlaWdodD0iNTEyIiA+PHBhdGggZD0iTTg4IDEyOGg0OHYyNTZIODh6bTE0NCAwaDQ4djI1NmgtNDh6bS03MiAxNmg0OHYyMjRoLTQ4em0xNDQgMGg0OHYyMjRoLTQ4em03Mi0xNmg0OHYyNTZoLTQ4eiIgc3Ryb2tlPSIjMjFDQkNFIiBmaWxsPSIjMjFDQkNFIj48L3BhdGg+PHBhdGggZD0iTTEwNCAxMDRWNTZIMTZ2NDAwaDg4di00OEg2NFYxMDR6bTMwNC00OHY0OGg0MHYzMDRoLTQwdjQ4aDg4VjU2eiIgc3Ryb2tlPSIjMjFDQkNFIiBmaWxsPSIjMjFDQkNFIj48L3BhdGg+PC9zdmc+)]() [![BibTeX](https://img.shields.io/badge/BibTeX-Citation-eeeeee?style=flat-square)](https://steve-zeyu-zhang.github.io/MotionAvatar/static/scholar.html)<br>
> <img src="https://github.com/steve-zeyu-zhang/MotionAvatar/blob/main/static/images/main-1.svg" width="600">

> **JointViT: Modeling Oxygen Saturation Levels with Joint Supervision on Long-Tailed OCTA**<br>
> [_**MIUA 2024 Oral**_](https://miua2024.github.io/)<br>
> [![Website](https://img.shields.io/badge/Website-Demo-fedcba?style=flat-square)](https://steve-zeyu-zhang.github.io/JointViT/) [![arXiv](https://img.shields.io/badge/arXiv-2404.11525-b31b1b?style=flat-square&logo=arxiv)](https://arxiv.org/abs/2404.11525) [![GitHub](https://img.shields.io/badge/GitHub-Code-1f883d?style=flat-square&logo=github)](https://github.com/steve-zeyu-zhang/JointViT) [![Papers With Code](https://img.shields.io/badge/Papers%20With%20Code-555555.svg?style=flat-square&logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2aWV3Qm94PSIwIDAgNTEyIDUxMiIgd2lkdGg9IjUxMiIgIGhlaWdodD0iNTEyIiA+PHBhdGggZD0iTTg4IDEyOGg0OHYyNTZIODh6bTE0NCAwaDQ4djI1NmgtNDh6bS03MiAxNmg0OHYyMjRoLTQ4em0xNDQgMGg0OHYyMjRoLTQ4em03Mi0xNmg0OHYyNTZoLTQ4eiIgc3Ryb2tlPSIjMjFDQkNFIiBmaWxsPSIjMjFDQkNFIj48L3BhdGg+PHBhdGggZD0iTTEwNCAxMDRWNTZIMTZ2NDAwaDg4di00OEg2NFYxMDR6bTMwNC00OHY0OGg0MHYzMDRoLTQwdjQ4aDg4VjU2eiIgc3Ryb2tlPSIjMjFDQkNFIiBmaWxsPSIjMjFDQkNFIj48L3BhdGg+PC9zdmc+)](https://paperswithcode.com/paper/jointvit-modeling-oxygen-saturation-levels) [![BibTeX](https://img.shields.io/badge/BibTeX-Citation-eeeeee?style=flat-square)](https://steve-zeyu-zhang.github.io/JointViT/static/scholar.html)<br>
> <img src="https://github.com/steve-zeyu-zhang/JointViT/blob/main/static/images/jointvit.svg" width="500"><br>

> **SegReg: Segmenting OARs by Registering MR Images and CT Annotations**<br>
> [_**ISBI 2024**_](https://biomedicalimaging.org/2024/)<br>
> [![Website](https://img.shields.io/badge/Website-Demo-fedcba?style=flat-square)](https://steve-zeyu-zhang.github.io/SegReg) [![arXiv](https://img.shields.io/badge/arXiv-2311.06956-b31b1b?style=flat-square&logo=arxiv)](https://arxiv.org/abs/2311.06956) [![OpenReview](https://img.shields.io/badge/OpenReview-8c1b13?style=flat-square)](https://openreview.net/forum?id=rC8bmJoOOTC) [![GitHub](https://img.shields.io/badge/GitHub-Code-1f883d?style=flat-square&logo=github)](https://github.com/steve-zeyu-zhang/SegReg) [![Papers With Code](https://img.shields.io/badge/Papers%20With%20Code-555555.svg?style=flat-square&logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2aWV3Qm94PSIwIDAgNTEyIDUxMiIgd2lkdGg9IjUxMiIgIGhlaWdodD0iNTEyIiA+PHBhdGggZD0iTTg4IDEyOGg0OHYyNTZIODh6bTE0NCAwaDQ4djI1NmgtNDh6bS03MiAxNmg0OHYyMjRoLTQ4em0xNDQgMGg0OHYyMjRoLTQ4em03Mi0xNmg0OHYyNTZoLTQ4eiIgc3Ryb2tlPSIjMjFDQkNFIiBmaWxsPSIjMjFDQkNFIj48L3BhdGg+PHBhdGggZD0iTTEwNCAxMDRWNTZIMTZ2NDAwaDg4di00OEg2NFYxMDR6bTMwNC00OHY0OGg0MHYzMDRoLTQwdjQ4aDg4VjU2eiIgc3Ryb2tlPSIjMjFDQkNFIiBmaWxsPSIjMjFDQkNFIj48L3BhdGg+PC9zdmc+)](https://paperswithcode.com/paper/segreg-segmenting-oars-by-registering-mr) [![BibTeX](https://img.shields.io/badge/BibTeX-Citation-eeeeee?style=flat-square)](https://steve-zeyu-zhang.github.io/SegReg/webpage/scholar.html)<br>
> <img src="https://github.com/steve-zeyu-zhang/steve-zeyu-zhang/blob/main/asset/segreg.svg" width="500"><br>
> <img src="https://github.com/steve-zeyu-zhang/steve-zeyu-zhang/blob/main/asset/segreg2.svg" width="500">


> **BHSD: A 3D Multi-class Brain Hemorrhage Segmentation Dataset**<br>
> [_**MLMI 2023**_](https://sites.google.com/view/mlmi2023)<br>
> [![DOI](https://img.shields.io/badge/DOI-10.1007%2F978--3--031--45673--2__15-fcb520?style=flat-square&logo=doi)](https://doi.org/10.1007/978-3-031-45673-2_15) [![arXiv](https://img.shields.io/badge/arXiv-2308.11298-b31b1b?style=flat-square&logo=arxiv)](https://arxiv.org/abs/2308.11298) [![OpenReview](https://img.shields.io/badge/OpenReview-8c1b13?style=flat-square)](https://openreview.net/forum?id=R5951Pk_vlw) [![GitHub](https://img.shields.io/badge/GitHub-Code-1f883d?style=flat-square&logo=github)](https://github.com/White65534/BHSD) [![Kaggle](https://img.shields.io/badge/Kaggle-Dataset-20beff?style=flat-square&logo=kaggle)](https://www.kaggle.com/datasets/stevezeyuzhang/bhsd-dataset) [![Papers With Code](https://img.shields.io/badge/Papers%20With%20Code-555555.svg?style=flat-square&logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2aWV3Qm94PSIwIDAgNTEyIDUxMiIgd2lkdGg9IjUxMiIgIGhlaWdodD0iNTEyIiA+PHBhdGggZD0iTTg4IDEyOGg0OHYyNTZIODh6bTE0NCAwaDQ4djI1NmgtNDh6bS03MiAxNmg0OHYyMjRoLTQ4em0xNDQgMGg0OHYyMjRoLTQ4em03Mi0xNmg0OHYyNTZoLTQ4eiIgc3Ryb2tlPSIjMjFDQkNFIiBmaWxsPSIjMjFDQkNFIj48L3BhdGg+PHBhdGggZD0iTTEwNCAxMDRWNTZIMTZ2NDAwaDg4di00OEg2NFYxMDR6bTMwNC00OHY0OGg0MHYzMDRoLTQwdjQ4aDg4VjU2eiIgc3Ryb2tlPSIjMjFDQkNFIiBmaWxsPSIjMjFDQkNFIj48L3BhdGg+PC9zdmc+)](https://paperswithcode.com/paper/bhsd-a-3d-multi-class-brain-hemorrhage) [![Papers With Code](https://img.shields.io/badge/Papers%20With%20Code-Dataset-21cbce.svg?style=flat-square&logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2aWV3Qm94PSIwIDAgNTEyIDUxMiIgd2lkdGg9IjUxMiIgIGhlaWdodD0iNTEyIiA+PHBhdGggZD0iTTg4IDEyOGg0OHYyNTZIODh6bTE0NCAwaDQ4djI1NmgtNDh6bS03MiAxNmg0OHYyMjRoLTQ4em0xNDQgMGg0OHYyMjRoLTQ4em03Mi0xNmg0OHYyNTZoLTQ4eiIgc3Ryb2tlPSIjMjFDQkNFIiBmaWxsPSIjMjFDQkNFIj48L3BhdGg+PHBhdGggZD0iTTEwNCAxMDRWNTZIMTZ2NDAwaDg4di00OEg2NFYxMDR6bTMwNC00OHY0OGg0MHYzMDRoLTQwdjQ4aDg4VjU2eiIgc3Ryb2tlPSIjMjFDQkNFIiBmaWxsPSIjMjFDQkNFIj48L3BhdGg+PC9zdmc+)](https://paperswithcode.com/dataset/bhsd) [![BibTeX](https://img.shields.io/badge/BibTeX-Citation-eeeeee?style=flat-square)](https://github.com/White65534/BHSD/tree/main#citation)<br>
> <img src="https://github.com/steve-zeyu-zhang/steve-zeyu-zhang/blob/main/asset/bhsd.svg" width="500">

> **A Deep Learning Approach to Diabetes Diagnosis**<br>
> [_**ACIIDS 2024**_](https://aciids.pwr.edu.pl/2024/)<br>
> [![Website](https://img.shields.io/badge/Website-Demo-fedcba?style=flat-square)](https://steve-zeyu-zhang.github.io/DiabetesDiagnosis) [![arXiv](https://img.shields.io/badge/arXiv-2403.07483-b31b1b?style=flat-square&logo=arxiv)](https://arxiv.org/abs/2403.07483) [![GitHub](https://img.shields.io/badge/GitHub-Code-1f883d?style=flat-square&logo=github)](https://github.com/steve-zeyu-zhang/DiabetesDiagnosis) [![Papers With Code](https://img.shields.io/badge/Papers%20With%20Code-555555.svg?style=flat-square&logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB2aWV3Qm94PSIwIDAgNTEyIDUxMiIgd2lkdGg9IjUxMiIgIGhlaWdodD0iNTEyIiA+PHBhdGggZD0iTTg4IDEyOGg0OHYyNTZIODh6bTE0NCAwaDQ4djI1NmgtNDh6bS03MiAxNmg0OHYyMjRoLTQ4em0xNDQgMGg0OHYyMjRoLTQ4em03Mi0xNmg0OHYyNTZoLTQ4eiIgc3Ryb2tlPSIjMjFDQkNFIiBmaWxsPSIjMjFDQkNFIj48L3BhdGg+PHBhdGggZD0iTTEwNCAxMDRWNTZIMTZ2NDAwaDg4di00OEg2NFYxMDR6bTMwNC00OHY0OGg0MHYzMDRoLTQwdjQ4aDg4VjU2eiIgc3Ryb2tlPSIjMjFDQkNFIiBmaWxsPSIjMjFDQkNFIj48L3BhdGg+PC9zdmc+)](https://paperswithcode.com/paper/a-deep-learning-approach-to-diabetes) [![BibTeX](https://img.shields.io/badge/BibTeX-Citation-eeeeee?style=flat-square)](https://steve-zeyu-zhang.github.io/DiabetesDiagnosis/static/scholar.html)<br>
> <img src="https://github.com/steve-zeyu-zhang/steve-zeyu-zhang/blob/main/asset/diabetes.svg" width="500">


## People




<table>
<tbody>
<tr>
<td align="center" valign="top" width="14.28%"><a href="https://github.com/Richardqiyi"><img src="/avatar/qiyi.jpeg" width="100px;"/><br /><b>QIYI</b></a></td>
<td align="center" valign="top" width="14.28%"><a href="https://github.com/huangjiayu-zju"><img src="/avatar/jiayu.jpeg" width="100px;"/><br /><b>Jiayu</b></a></td>
<td align="center" valign="top" width="14.28%"><a href="https://scholar.google.com/citations?user=Y3SBBWMAAAAJ&hl=en&oi=sra"><img src="/avatar/biao.jpeg" width="100px;"/><br /><b>Biao</b></a></td>
<td align="center" valign="top" width="14.28%"><a href="https://github.com/hycarbon-b"><img src="https://avatars.githubusercontent.com/u/63985695?v=4" width="100px;"/><br /><b>Chen</b></a></td>
<td align="center" valign="top" width="14.28%"><a href="https://github.com/lgX1123"><img src="/avatar/lgx.jpeg" width="100px;"/><br /><b>lgx</b></a></td>
<td align="center" valign="top" width="14.28%"><a href="https://steve-zeyu-zhang.github.io/"><img src="/avatar/steve.jpg" width="100px;"/><br /><b>Steve</b></a></td>
<td align="center" valign="top" width="14.28%"><a href="https://github.com/ZeroHzzzz"><img src="https://avatars.githubusercontent.com/u/137389489?v=4" width="100px;"/><br /><b>ZeroHzzzz</b></a></td>
</tr>
  <tr>
<td align="center" valign="top" width="14.28%"><a href="https://github.com/Showwwwwwwww"><img src="/avatar/shawn.jpeg" width="100px;"/><br /><b>Shawn</b></a></td>
<td align="center" valign="top" width="14.28%"><a href="https://github.com/u7079256"><img src="/avatar/ken.jpeg" width="100px;"/><br /><b>Ken</b></a></td>
<td align="center" valign="top" width="14.28%"><a href="https://github.com/Tiooo111"><img src="/avatar/zhiyuan.jpeg" width="100px;"/><br /><b>Zhiyuan</b></a></td>
<td align="center" valign="top" width="14.28%"><a href="https://github.com/malie-wang"><img src="https://avatars.githubusercontent.com/u/100657314?v=4" width="100px;"/><br /><b>Malie</b></a></td>
<td align="center" valign="top" width="14.28%"><a href="https://github.com/KaiqiLin"><img src="/avatar/kaiqi.jpeg" width="100px;"/><br /><b>Kaiqi</b></a></td>
<td align="center" valign="top" width="14.28%"><a href="https://github.com/gekelly"><img src="https://avatars.githubusercontent.com/u/37037628?v=4" width="100px;"/><br /><b>Shiya</b></a></td>
<td align="center" valign="top" width="14.28%"><a href="https://github.com/wangjiameiiii"><img src="/avatar/jiamei.jpeg" width="100px;"/><br /><b>Jiamei</b></a></td>
</tr>
  <tr>
<td align="center" valign="top" width="14.28%"><a href="https://github.com/jingxianer"><img src="/avatar/anan.jpeg" width="100px;"/><br /><b>anan</b></a></td>
</tr>
</tbody>
</table>

## Contact

- Email: ai.geeks@groups.outlook.com


